<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Taewoo Kim - Researcher</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<style>
  body { 
      font-family: Arial, sans-serif; 
      max-width: 900px; 
      margin: auto; 
      padding: 20px; 
      line-height: 1.6; 
  }
  h1 { margin-bottom: 5px; }
  h2 { 
      margin-top: 40px; 
      border-bottom: 2px solid #eee; 
      padding-bottom: 5px; 
  }
  .pub-item { margin-bottom: 18px; }
  .year { color: #555; font-weight: bold; }
  .award { color: #d14; font-weight: bold; }
  .edu-item { margin-bottom: 20px; }

  /* üî• ÎßÅÌÅ¨ ÏÉâ Ï†úÍ±∞ ‚Äî Í∏ÄÏûêÏôÄ ÎèôÏùºÌïòÍ≤å */
  a { 
      color: inherit; 
      text-decoration: none; 
  }

.top-links a {
    color: #007acc;   /* ÎÑàÍ∞Ä ÏõêÌïòÎäî ÏÉâ */
    font-weight: bold;
}

.educ-entry {
    display: flex;
    justify-content: space-between;
    align-items: baseline;
    font-weight: bold;
}

.educ-sub {
  font-style: italic;
  color: #555;
  margin: 0;
  padding: 0;
}


  /* Optional: hover ÏãúÎßå ÏÇ¥Ïßù ÌöåÏÉâ */
  a:hover {
      color: #555;
  }
</style>
</head>

<body>

<!-- HEADER with Photo + Name + Links -->
<div style="display: flex; align-items: center; gap: 20px; margin-bottom: 20px;">
  <img src="profile.png" alt="Profile Photo" 
       style="width: 180px; height: 180px; border-radius: 10px; object-fit: cover; margin-top: 20px;">
  
  <div>
    <h1 style="margin-bottom: 8px;">Taewoo Kim</h1>
    <p style="margin: 0;">Senior Engineer, Qualcomm</p>
    <p style="margin: 4px 0;">Email: an625148 (at) gmail.com</p>

    <p style="margin: 0;" class="top-links">
      <a href="https://www.linkedin.com/in/taewookim-a85270168/">LinkedIn</a> ¬∑
      <a href="https://scholar.google.com/citations?user=SzKw5oYAAAAJ&hl=en">Google Scholar</a> ¬∑
      <a href="https://github.com/intelpro">GitHub</a>
    </p>
  </div>
</div>




<!-- ABOUT -->
<h2>About</h2>
<p>
I am a <b>Senior Engineer</b> at Qualcomm Korea, developing ML-based computational imaging and camera algorithms.
Before joining Qualcomm, I completed my Ph.D. at KAIST under the supervision of 
<b>Prof. Kuk-Jin Yoon</b>, where I worked on <b>computer vision</b>, <b>machine learning</b>, and 
<b>computational photography</b>.
My recent research interests include <b>Generative AI</b> (image/video generation), 
<b>computational photography</b>, and <b>multi-modal data fusion</b>.
</p>

<!-- EDUCATION -->
<h2>Education</h2>

<div class="edu-item">
  <div class="educ-entry">
    <span><b>Ph.D. in Mechanical Engineering</b>, KAIST</span>
    <span>Feb.2025</span>
  </div>
  <span class="educ-sub">- Thesis: Video Enhancement with Event Cameras</span><br>
  <span class="educ-sub">- Advisor: Prof. Kuk-Jin Yoon</span>
</div>

<div class="edu-item">
  <div class="educ-entry">
    <span><b>M.S. in Robotics</b>, KAIST</span>
    <span>Feb.2020</span>
  </div>
  <span class="educ-sub">- Thesis: Joint Unsupervised Disparity and Optical Flow Estimation of Stereo Videos with Loop Consistency</span><br>
  <span class="educ-sub">- Advisor: Prof. Kuk-Jin Yoon</span>
</div>

<div class="edu-item">
  <div class="educ-entry">
    <span><b>B.S. in Mechanical Engineering</b>, Yonsei University</span>
    <span>Feb.2017</span>
  </div>
</div>


<!-- PUBLICATIONS -->
<h2>Publications</h2>

<div class="pub-item">
  <span class="year">ICCV 2025</span><br>
  <b>Event-guided Unified Framework for Low-light Video Enhancement, Frame Interpolation, and Deblurring</b><br>
  <b>Taewoo Kim</b>, Kuk-Jin Yoon<br>
  <a href="https://openaccess.thecvf.com/content/ICCV2025/papers/Kim_Event-guided_Unified_Framework_for_Low-light_Video_Enhancement_Frame_Interpolation_and_ICCV_2025_paper.pdf">
    [<span style="color:#007acc;">Paper</span>]
  </a>
</div>

<div class="pub-item">
  <span class="year">NeurIPS 2024</span><br>
  <b>A Benchmark Dataset for Event-Guided Human Pose Estimation and Tracking in Extreme Conditions</b><br>
  Hoonhee Cho*, <b>Taewoo Kim*</b>, Yuwhan Jeong, Kuk-Jin Yoon<br>
  <a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/f304e427cfe6bb762fe1bf18516c8a87-Paper-Datasets_and_Benchmarks_Track.pdf">
    [<span style="color:#007acc;">Paper</span>]
  </a>
</div>

<div class="pub-item">
  <span class="year">ECCV 2024</span><br>
  <b>Towards Real-world Event-guided Low-light Video Enhancement and Deblurring</b><br>
  <b>Taewoo Kim</b>, Jaeseok Jeong, Hoonhee Cho, Yuhwan Jeong, Kuk-Jin Yoon<br>
  <a href="https://arxiv.org/pdf/2408.14916">
    [<span style="color:#007acc;">Paper</span>]
  </a>
</div>

<div class="pub-item">
  <span class="year">ECCV 2024</span><br>
  <b>CMTA: Cross-Modal Temporal Alignment for Event-guided Video Deblurring</b><br>
  <b>Taewoo Kim*</b>, Hoonhee Cho*, Kuk-Jin Yoon<br>
  <a href="https://arxiv.org/pdf/2408.14930">
    [<span style="color:#007acc;">Paper</span>]
  </a>
</div>

<div class="pub-item">
  <span class="year">CVPR 2024</span><br>
  <b>Frequency-aware Event-based Video Deblurring for Real-world Motion Blur</b><br>
  <b>Taewoo Kim*</b>, Hoonhee Cho*, Kuk-Jin Yoon<br>
  <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Kim_Frequency-aware_Event-based_Video_Deblurring_for_Real-World_Motion_Blur_CVPR_2024_paper.pdf">
    [<span style="color:#007acc;">Paper</span>]
  </a>
</div>

<div class="pub-item">
  <span class="year">CVPR 2024</span><br>
  <b>TTA-EVF: Test-Time Adaptation for Event-based Video Frame Interpolation via Reliable Pixel and Sample Estimation</b><br>
  Hoonhee Cho, <b>Taewoo Kim</b>, Yuhwan Jeong, Kuk-Jin Yoon<br>
  <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Cho_TTA-EVF_Test-Time_Adaptation_for_Event-based_Video_Frame_Interpolation_via_Reliable_CVPR_2024_paper.pdf">
    [<span style="color:#007acc;">Paper</span>]
  </a>
</div>

<div class="pub-item">
  <span class="year">ICCV 2023</span><br>
  <b>Non-coaxial Event-Guided Motion Deblurring with Spatial Alignment</b><br>
  Hoonhee Cho, Yuhwan Jeong, <b>Taewoo Kim</b>, Kuk-Jin Yoon<br>
  <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_Non-Coaxial_Event-Guided_Motion_Deblurring_with_Spatial_Alignment_ICCV_2023_paper.pdf">
    [<span style="color:#007acc;">Paper</span>]
  </a>
</div>

<div class="pub-item">
  <span class="year">CVPR 2023</span><br>
  <b>Event-based Video Frame Interpolation with Cross-Modal Asymmetric Bidirectional Motion Fields</b><br>
  <b>Taewoo Kim</b>, Yujeong Chae, Hyun-Kurl Jang, Kuk-Jin Yoon<br>
  <span class="award">Highlight Paper (Top 2.5%)</span><br>
  <a href="https://arxiv.org/pdf/2502.13716">
    [<span style="color:#007acc;">Paper</span>]
  </a>
</div>

<div class="pub-item">
  <span class="year">ECCV 2022</span><br>
  <b>Event-guided Deblurring of Unknown Exposure Time Videos</b><br>
  <b>Taewoo Kim</b>, Jeongmin Lee, Wang Lin, Kuk-Jin Yoon<br>
  <span class="award">Oral Presentation (Top 2.7%)</span><br>
  <a href="https://arxiv.org/abs/2112.06988">
    [<span style="color:#007acc;">Paper</span>]
  </a>
</div>

<div class="pub-item">
  <span class="year">RA-L + IROS 2020</span><br>
  <b>Loop-Net: Joint Unsupervised Disparity and Optical Flow Estimation of Stereo Videos with Spatiotemporal Loop Consistency</b><br>
  <b>Taewoo Kim</b>, Kwonyoung Ryu, Kyeongseob Song, Kuk-Jin Yoon<br>
  <span class="award">Oral Presentation</span><br>
  <a href="https://ieeexplore.ieee.org/document/9140315">
    [<span style="color:#007acc;">Paper</span>]
  </a>
</div>


<!-- AWARDS -->
<h2>Awards</h2>
<ul style="list-style-type: none; padding-left: 0; margin-top: 10px;">
  <li><b>CVPR 2023 Highlight Paper</b> ‚Äî Top 2.5% of all submissions</li>
  <li><b>ECCV 2022 Oral Presentation</b> ‚Äî Top 2.7% of all submissions</li>
  <li><b>IPIU 2023 Gold Prize</b> ‚Äî Second Best Paper Award</li>
</ul>

<!-- REVIEWER SERVICES -->
<h2>Reviewer Services</h2>
<ul style="list-style-type: none; padding-left: 0; margin-top: 10px;">
  <li><b>Conferences:</b> CVPR, ICCV, ECCV, WACV, NeurIPS, SIGGRAPH Asia</li>
  <li><b>Journals:</b> IEEE TPAMI, IJCV, Neural Networks, RA-L, IJAT</li>
</ul>

<!-- CONTACT -->
<h2>Contact</h2>
<p>Email: an625148 (at) gmail.com</p>

<p style="text-align:center; color:#888; margin-top:50px;">
  ¬© 2025 Taewoo Kim
</p>

</body>
</html>
