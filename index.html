<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Taewoo Kim - Researcher</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<style>
  body { 
      font-family: Arial, sans-serif; 
      max-width: 900px; 
      margin: auto; 
      padding: 20px; 
      line-height: 1.6; 
  }
  h1 { margin-bottom: 5px; }
  h2 { 
      margin-top: 40px; 
      border-bottom: 2px solid #eee; 
      padding-bottom: 5px; 
  }
  .pub-item { margin-bottom: 18px; }
  .year { color: #555; font-weight: bold; }
  .award { color: #d14; font-weight: bold; }
  .edu-item { margin-bottom: 20px; }

  /* ğŸ”¥ ë§í¬ ìƒ‰ ì œê±° â€” ê¸€ìì™€ ë™ì¼í•˜ê²Œ */
  a { 
      color: inherit; 
      text-decoration: none; 
  }

.top-links a {
    color: #007acc;   /* ë„ˆê°€ ì›í•˜ëŠ” ìƒ‰ */
    font-weight: bold;
}

  /* Optional: hover ì‹œë§Œ ì‚´ì§ íšŒìƒ‰ */
  a:hover {
      color: #555;
  }
</style>
</head>

<body>

<!-- HEADER with Photo + Name + Links -->
<div style="display: flex; align-items: center; gap: 20px; margin-bottom: 20px;">
  <img src="profile.png" alt="Profile Photo" 
       style="width: 180px; height: 180px; border-radius: 10px; object-fit: cover; margin-top: 20px;">
  
  <div>
    <h1 style="margin-bottom: 8px;">Taewoo Kim</h1>
    <p style="margin: 0;">Senior Engineer, Qualcomm</p>
    <p style="margin: 4px 0;">Email: an625148@gmail.com</p>

    <p style="margin: 0;" class="top-links">
      <a href="https://www.linkedin.com/in/taewookim-a85270168/">LinkedIn</a> Â·
      <a href="https://scholar.google.com/citations?user=SzKw5oYAAAAJ&hl=en">Google Scholar</a> Â·
      <a href="https://github.com/intelpro">GitHub</a>
    </p>
  </div>
</div>




<!-- ABOUT -->
<h2>About</h2>
<p>
I am a <b>Senior Engineer</b> in the <b>Camera Algorithm Design</b> team at Qualcomm. 
Before joining Qualcomm, I completed my Ph.D. at KAIST under the supervision of 
<b>Prof. Kuk-Jin Yoon</b>, where I worked on <b>computer vision</b>, <b>machine learning</b>, and 
<b>computational imaging</b>.
My recent research interests include <b>Generative AI</b> (image/video generation), 
<b>computational photography</b>, and <b>multi-modal data fusion</b>.
</p>


<!-- EDUCATION -->
<h2>Education</h2>

<div class="edu-item">
  <b>Ph.D. in Mechanical Engineering</b>, KAIST, Daejeon, South Korea <br>
  <i>Mar. 2020 â€“ Feb. 2025</i><br>
  Thesis: <i>Video Enhancement with Event Cameras</i><br>
  Advisor: Prof. Kuk-Jin Yoon
</div>

<div class="edu-item">
  <b>M.S. in Robotics</b>, KAIST, Daejeon, South Korea <br>
  <i>Feb. 2018 â€“ Feb. 2020</i><br>
  Thesis: <i>Joint Unsupervised Disparity and Optical Flow Estimation of Stereo Videos with Loop Consistency</i><br>
  Advisor: Prof. Kuk-Jin Yoon
</div>

<div class="edu-item">
  <b>B.S. in Mechanical Engineering</b>, Yonsei University, Seoul, South Korea <br>
  <i>Feb. 2017</i>
</div>


<!-- PUBLICATIONS -->
<h2>Publications</h2>

<div class="pub-item">
  <span class="year">ICCV 2025</span><br>
  <b>Event-guided Unified Framework for Low-light Video Enhancement, Frame Interpolation, and Deblurring</b>
  <a href="https://openaccess.thecvf.com/content/ICCV2025/papers/Kim_Event-guided_Unified_Framework_for_Low-light_Video_Enhancement_Frame_Interpolation_and_ICCV_2025_paper.pdf">[ğŸ ]</a><br>
  Taewoo Kim, Kuk-Jin Yoon
</div>

<div class="pub-item">
  <span class="year">NeurIPS 2024</span><br>
  <b>A Benchmark Dataset for Event-Guided Human Pose Estimation and Tracking in Extreme Conditions</b>
  <a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/f304e427cfe6bb762fe1bf18516c8a87-Paper-Datasets_and_Benchmarks_Track.pdf">[ğŸ ]</a><br>
  Hoonhee Cho, Taewoo Kim, Yuwhan Jeong, Kuk-Jin Yoon
</div>

<div class="pub-item">
  <span class="year">ECCV 2024</span><br>
  <b>Towards Real-world Event-guided Low-light Video Enhancement and Deblurring</b>
  <a href="https://arxiv.org/pdf/2408.14916">[ğŸ ]</a><br>
  Taewoo Kim, Jaeseok Jeong, Hoonhee Cho, Yuhwan Jeong, Kuk-Jin Yoon
</div>

<div class="pub-item">
  <span class="year">ECCV 2024</span><br>
  <b>CMTA: Cross-Modal Temporal Alignment for Event-guided Video Deblurring</b>
  <a href="https://arxiv.org/pdf/2408.14930">[ğŸ ]</a><br>
  Taewoo Kim, Hoonhee Cho, Kuk-Jin Yoon
</div>

<div class="pub-item">
  <span class="year">CVPR 2024</span><br>
  <b>Frequency-aware Event-based Video Deblurring for Real-world Motion Blur</b>
  <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Kim_Frequency-aware_Event-based_Video_Deblurring_for_Real-World_Motion_Blur_CVPR_2024_paper.pdf">[ğŸ ]</a><br>
  Taewoo Kim, Hoonhee Cho, Kuk-Jin Yoon
</div>

<div class="pub-item">
  <span class="year">CVPR 2024</span><br>
  <b>TTA-EVF: Test-Time Adaptation for Event-based Video Frame Interpolation via Reliable Pixel and Sample Estimation</b>
  <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Cho_TTA-EVF_Test-Time_Adaptation_for_Event-based_Video_Frame_Interpolation_via_Reliable_CVPR_2024_paper.pdf">[ğŸ ]</a><br>
  Hoonhee Cho, Taewoo Kim, Yuhwan Jeong, Kuk-Jin Yoon
</div>

<div class="pub-item">
  <span class="year">ICCV 2023</span><br>
  <b>Non-coaxial Event-Guided Motion Deblurring with Spatial Alignment</b>
  <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_Non-Coaxial_Event-Guided_Motion_Deblurring_with_Spatial_Alignment_ICCV_2023_paper.pdf">[ğŸ ]</a><br>
  Hoonhee Cho, Yuhwan Jeong, Taewoo Kim, Kuk-Jin Yoon
</div>

<div class="pub-item">
  <span class="year">CVPR 2023</span><br>
  <b>Event-based Video Frame Interpolation with Cross-Modal Asymmetric Bidirectional Motion Fields</b>
  <a href="https://arxiv.org/pdf/2502.13716">[ğŸ ]</a><br>
  Taewoo Kim, Yujeong Chae, Hyun-Kurl Jang, Kuk-Jin Yoon<br>
  <span class="award">Highlight Paper (Top 2.5%)</span>
</div>

<div class="pub-item">
  <span class="year">ECCV 2022</span><br>
  <b>Event-guided Deblurring of Unknown Exposure Time Videos</b>
  <a href="https://arxiv.org/abs/2112.06988">[ğŸ ]</a><br>
  Taewoo Kim, Jeongmin Lee, Wang Lin, Kuk-Jin Yoon<br>
  <span class="award">Oral Presentation (Top 2.7%)</span>
</div>

<div class="pub-item">
  <span class="year">RA-L + IROS 2020</span><br>
  <b>Loop-Net: Joint Unsupervised Disparity and Optical Flow Estimation of Stereo Videos with Spatiotemporal Loop Consistency</b>
  <a href="https://ieeexplore.ieee.org/document/9140315">[ğŸ ]</a><br>
  Taewoo Kim, Kwonyoung Ryu, Kyeongseob Song, Kuk-Jin Yoon<br>
  <span class="award">Oral Presentation</span>
</div>



<!-- AWARDS -->
<h2>Awards</h2>
<ul style="list-style-type: none; padding-left: 0; margin-top: 10px;">
  <li><b>CVPR 2023 Highlight Paper</b> â€” Top 2.5% of all submissions</li>
  <li><b>ECCV 2022 Oral Presentation</b> â€” Top 2.7% of all submissions</li>
  <li><b>IPIU 2023 Gold Prize</b> â€” Second Best Paper Award</li>
</ul>

<!-- REVIEWER SERVICES -->
<h2>Reviewer Services</h2>
<ul style="list-style-type: none; padding-left: 0; margin-top: 10px;">
  <li><b>Conferences:</b> CVPR, ICCV, ECCV, WACV, NeurIPS, SIGGRAPH Asia</li>
  <li><b>Journals:</b> IEEE TPAMI, IJCV, Neural Networks, RA-L, IJAT</li>
</ul>

<!-- CONTACT -->
<h2>Contact</h2>
<p>Email: an625148@gmail.com</p>

<p style="text-align:center; color:#888; margin-top:50px;">
  Â© 2025 Taewoo Kim
</p>

</body>
</html>
